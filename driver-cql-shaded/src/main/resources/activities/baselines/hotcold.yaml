description: |
  A set of named scenarios for testing cache performance.
  This is a set of named scenarios packaged as a workload file that can
  be used to test datasets of different sizes. This workload file
  contains no specific workloads of its own. It is expected to be used
  with existing workload definitions. By default, it will use
  the cql-tabular2 workload.
  Going forward, some conventions will be established about what parameters
  mean for dataset sizing. For now, the names used in cql-tabular2 will be
  the standard. For now, this means partsize and partcount.
  partsize is used to modulo the selected partition for a row write
  partcount is used to modulo a pseudo-random row selector to fall within the
  known dataset size for extant data. These must be calculated together
  to ensure that reads address valid data by default. Some partially empty
  read ratio can be configured by adjusting these parameters with respect to
  known dataset sizes.
  The scenario names are suggestive of the dataset size with basic exponents.
  For example 1e5 means 100000.
  Defaults:
    rows (dataset size basis)
    partsize: rows/100
    partcount: rows/100


scenarios:
  hotcold1e5:
    schema_1e5: TEMPLATE(workload,cql-tabular2) schema
    rampup_1e5: TEMPLATE(workload,cql-tabular2) rampup rampup-cycles=TEMPLATE(rows,1e5) partsize=TEMPLATE(partsize,1e3)
    main_1e5: TEMPLATE(workload,cql-tabular2) main main-cycles=TEMPLATE(rows,1e5) partcount=TEMPLATE(partcount,1e3)

